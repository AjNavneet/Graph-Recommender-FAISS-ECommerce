{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6866db",
   "metadata": {},
   "source": [
    "## DeepWalk Methodology\n",
    "\n",
    "DeepWalk is an approach used to represent the nodes of a graph in an n-dimensional vector space, capturing the social relations within the graph. It leverages local information in the network by employing Random Walks to traverse the graph.\n",
    "\n",
    "In a Random Walk, you start from a specific node and then randomly choose one of its neighbors to add to the path. This process continues for a desired number of steps. Let's illustrate this with an example.\n",
    "\n",
    "Consider the directed and unweighted graph shown above. Suppose we start a Random Walk at Node A, and the length of the walk is set to 4. From Node A, we can visit Node B, resulting in the path [A, B]. From Node B, we can choose to move to Node E or even go back to Node A. If we choose to go to Node E, the path becomes [A, B, E]. From Node E, we can further choose to go to Node F or Node C. Let's say we opt for Node F, creating a Random Walk of length 4, like this: **[A, B, E, F]**.\n",
    "\n",
    "Each Random Walk is essentially a sequence of nodes, akin to a sentence in text, where each node serves as a word in the sentence.\n",
    "\n",
    "In DeepWalk, you generate Random Walks of a fixed length \"l\" a specific number of times \"m\" from each node. This process results in a total of \"number_of_nodes * m\" sequences, each of length \"l\". These sequences can be used in conjunction with the skip-gram approach to train a Word2Vec model.\n",
    "\n",
    "For more insights on Word2Vec, you can refer to JayAlammar's blog post on [Word2Vec](https://jalammar.github.io/illustrated-word2vec/).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa27f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undirected_weighted_product_views_graph.parquet 10 50\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pecanpy import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "from Constants import Constants\n",
    "\n",
    "# Import libraries for progress tracking, joblib, etc.\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "\n",
    "# Initialize constants and variables\n",
    "\n",
    "# The name of the graph file\n",
    "GRAPH_FILE_NAME = Constants.GRAPH_FILE_NAME.value\n",
    "\n",
    "# Constants for configuring the graph construction\n",
    "WEIGHTED = Constants.WEIGHTED.value  # Weighted or unweighted graph\n",
    "DIRECTED = Constants.DIRECTED.value  # Directed or undirected graph\n",
    "\n",
    "# Number of walks to generate\n",
    "NUM_WALK = Constants.NUM_WALK.value\n",
    "\n",
    "# Length of each walk\n",
    "WALK_LEN = Constants.WALK_LEN.value\n",
    "\n",
    "# Print the initialized constants and variables for reference\n",
    "print(GRAPH_FILE_NAME, NUM_WALK, WALK_LEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9a8e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ad283",
   "metadata": {},
   "source": [
    "### Let us consider undirected_weighted_product_views_graph to Generate RandomWalk Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea276435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Read from ../Data/ConstructedGraph/undirected_weighted_product_views_graph.parquet\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the graph file using the GRAPH_FILE_NAME\n",
    "graph_path = '../Data/ConstructedGraph/{}'.format(GRAPH_FILE_NAME)\n",
    "\n",
    "# Read the graph data from the specified Parquet file.\n",
    "graph = pd.read_parquet(graph_path)\n",
    "\n",
    "print(\"Graph Read from {}\".format(graph_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4713a417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid_1</th>\n",
       "      <th>pid_2</th>\n",
       "      <th>occurence_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3601512</td>\n",
       "      <td>3601269</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100059274</td>\n",
       "      <td>3601306</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5100855</td>\n",
       "      <td>4804056</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100041977</td>\n",
       "      <td>100041934</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100057579</td>\n",
       "      <td>100057560</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846587</th>\n",
       "      <td>12300752</td>\n",
       "      <td>4803895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846588</th>\n",
       "      <td>100017063</td>\n",
       "      <td>6501098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846589</th>\n",
       "      <td>8800741</td>\n",
       "      <td>1005195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846590</th>\n",
       "      <td>25200369</td>\n",
       "      <td>23900098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846591</th>\n",
       "      <td>100051139</td>\n",
       "      <td>100042051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6846592 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pid_1      pid_2  occurence_ct\n",
       "0          3601512    3601269            37\n",
       "1        100059274    3601306            12\n",
       "2          5100855    4804056           880\n",
       "3        100041977  100041934             2\n",
       "4        100057579  100057560            11\n",
       "...            ...        ...           ...\n",
       "6846587   12300752    4803895             1\n",
       "6846588  100017063    6501098             1\n",
       "6846589    8800741    1005195             1\n",
       "6846590   25200369   23900098             1\n",
       "6846591  100051139  100042051             1\n",
       "\n",
       "[6846592 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b65714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph undirected_weighted_product_views_graph.parquet has Nodes: 211861 | Edges: 6846592\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique nodes in the graph\n",
    "Node_Count = len(set(graph['pid_1'].unique()).union(graph['pid_2'].unique()))\n",
    "\n",
    "# Calculate the total number of edges in the graph\n",
    "Edge_Count = len(graph)\n",
    "\n",
    "print(\"Graph {} has Nodes: {} | Edges: {}\".format(GRAPH_FILE_NAME, Node_Count, Edge_Count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e2fc5",
   "metadata": {},
   "source": [
    "#### Save Graph in .edg format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff022648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edg Graph Saved\n"
     ]
    }
   ],
   "source": [
    "# Specify the path for the '.edg' graph file, based on the GRAPH_FILE_NAME\n",
    "edg_graph_path = '../Data/Edg_Graphs_DataFile/' + GRAPH_FILE_NAME.split('.')[0] + '.edg'\n",
    "\n",
    "# Save the graph data to the '.edg' file, using a tab ('\\t') as the separator.\n",
    "# The 'index' and 'header' are set to False to exclude the index and column names.\n",
    "graph.to_csv(edg_graph_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(\"Edg Graph Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183260d",
   "metadata": {},
   "source": [
    "### Graph Random Walk Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34f584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Node2Vec model for deep walk\n",
    "\n",
    "# 'p' and 'q' are parameters controlling the breadth-first search (BFS) and depth-first search (DFS) behavior.\n",
    "# In this configuration, 'p' is set to 1, indicating that BFS and DFS are equally important.\n",
    "\n",
    "g = node2vec.SparseOTF(p=1, q=1, workers=-1, verbose=True, extend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0892b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread #  6 progress: |###                      | 9.99 %\n",
      "Thread #  3 progress: |###                      | 9.99 %\n",
      "Thread #  7 progress: |###                      | 9.99 %\n",
      "Thread #  5 progress: |###                      | 9.99 %\n",
      "Thread #  8 progress: |###                      | 9.99 %\n",
      "Thread #  0 progress: |###                      | 9.99 %\n",
      "Thread #  1 progress: |###                      | 9.99 %\n",
      "Thread #  9 progress: |###                      | 9.99 %\n",
      "Thread #  4 progress: |###                      | 9.99 %\n",
      "Thread # 11 progress: |###                      | 9.99 %\n",
      "Thread #  2 progress: |###                      | 9.99 %\n",
      "Thread # 10 progress: |###                      | 9.99 %\n",
      "Thread #  6 progress: |#####                    | 19.99 %\n",
      "Thread #  3 progress: |#####                    | 19.99 %\n",
      "Thread #  5 progress: |#####                    | 19.99 %\n",
      "Thread #  7 progress: |#####                    | 19.99 %\n",
      "Thread #  9 progress: |#####                    | 19.99 %\n",
      "Thread #  1 progress: |#####                    | 19.99 %\n",
      "Thread #Thread #   2 progress: |#####                    | 19.99 %\n",
      "Thread # 11  0 progress:progress:  |#####                    | 19.99|#####                    | % \n",
      "19.99 %\n",
      "Thread #  8 progress: |#####                    | 19.99 %\n",
      "Thread #  4 progress: |#####                    | 19.99 %\n",
      "Thread # 10 progress: |#####                    | 19.99 %\n",
      "Thread #  6 progress: |########                 | 29.99 %\n",
      "Thread #  9 progress: |########                 | 29.99 %\n",
      "Thread #  3 progress: |########                 | 29.99 %\n",
      "Thread #  5 progress: |########                 | 29.99 %\n",
      "Thread # 11 progress: |########                 | 29.99 %\n",
      "Thread #  7 progress: |########                 | 29.99 %\n",
      "Thread #  2 progress: |########                 | 29.99 %\n",
      "Thread #  1 progress: |########                 | 29.99 %\n",
      "Thread #  0 progress: |########                 | 29.99 %\n",
      "Thread #  4 progress: |########                 | 29.99 %\n",
      "Thread #  8 progress: |########                 | 29.99 %\n",
      "Thread # 10 progress: |########                 | 29.99 %\n",
      "Thread #  9 progress: |##########               | 39.99 %\n",
      "Thread #  6 progress: |##########               | 39.99 %\n",
      "Thread #  3 progress: |##########               | 39.99 %\n",
      "Thread #  5 progress: |##########               | 39.99 %\n",
      "Thread #  4 progress: |##########               | 39.99 %\n",
      "Thread #  2 progress: |##########               | 39.99 %\n",
      "Thread #  1 progress: |##########               | 39.99 %\n",
      "Thread # 11 progress: |##########               | 39.99 %\n",
      "Thread #  7 progress: |##########               | 39.99 %\n",
      "Thread #  0 progress: |##########               | 39.99 %\n",
      "Thread #  8 progress: |##########               | 39.99 %\n",
      "Thread # 10 progress: |##########               | 39.99 %\n",
      "Thread #  4 progress: |#############            | 49.99 %\n",
      "Thread #  3 progress: |#############            | 49.99 %\n",
      "Thread #  9 progress: |#############            | 49.99 %\n",
      "Thread #  6 progress: |#############            | 49.99 %\n",
      "Thread #  5 progress: |#############            | 49.99 %\n",
      "Thread #  1 progress: |#############            | 49.99 %\n",
      "Thread #  7 progress: |#############            | 49.99 %\n",
      "Thread # 11 progress: |#############            | 49.99 %\n",
      "Thread #  2 progress: |#############            | 49.99 %\n",
      "Thread #  0 progress: |#############            | 49.99 %\n",
      "Thread #  8 progress: |#############            | 49.99 %\n",
      "Thread # 10 progress: |#############            | 49.99 %\n",
      "Thread #  9 progress: |###############          | 59.99 %\n",
      "Thread #  3 progress: |###############          | 59.99 %\n",
      "Thread #  6 progress: |###############          | 59.99 %\n",
      "Thread #  2 progress: |###############          | 59.99 %\n",
      "Thread # 11 progress: |###############          | 59.99 %\n",
      "Thread #  5 progress: |###############          | 59.99 %\n",
      "Thread #  0 progress: |###############          | 59.99 %\n",
      "Thread #  1 progress: |###############          | 59.99 %\n",
      "Thread #  4 progress: |###############          | 59.99 %\n",
      "Thread #  7 progress: |###############          | 59.99 %\n",
      "Thread #  8 progress: |###############          | 59.99 %\n",
      "Thread # 10 progress: |###############          | 59.99 %\n",
      "Thread #  9 progress: |##################       | 69.99 %\n",
      "Thread #  6 progress: |##################       | 69.99 %\n",
      "Thread #  3 progress: |##################       | 69.99 %\n",
      "Thread #  2 progress: |##################       | 69.99 %\n",
      "Thread # 11 progress: |##################       | 69.99 %\n",
      "Thread #  5 progress: |##################       | 69.99 %\n",
      "Thread #  0 progress: |##################       | 69.99 %\n",
      "Thread #  7 progress: |##################       | 69.99 %\n",
      "Thread #  4 progress: |##################       | 69.99 %\n",
      "Thread #  1 progress: Thread #  8 progress: |##################       | 69.99 %\n",
      "|##################       | 69.99 %\n",
      "Thread # 10 progress: |##################       | 69.99 %\n",
      "Thread #  9 progress: |####################     | 79.99 %\n",
      "Thread #  2 progress: |####################     | 79.99 %\n",
      "Thread #  6 progress: |####################     | 79.99 %\n",
      "Thread #  0 progress: |####################     | 79.99 %\n",
      "Thread #  5 progress: |####################     | 79.99 %\n",
      "Thread #  3 progress: |####################     | 79.99 %\n",
      "Thread #  4 progress: |####################     | 79.99 %\n",
      "Thread # 11 progress: |####################     | 79.99 %\n",
      "Thread #  7 progress: |####################     | 79.99 %\n",
      "Thread #  8 progress: |####################     | 79.99 %\n",
      "Thread #  1 progress: |####################     | 79.99 %\n",
      "Thread # 10 progress: |####################     | 79.99 %\n",
      "Thread #  9 progress: |#######################  | 89.99 %\n",
      "Thread #  0 progress: |#######################  | 89.99 %\n",
      "Thread #  2 progress: |#######################  | 89.99 %\n",
      "Thread #  5 progress: |#######################  | 89.99 %\n",
      "Thread #  6 progress: |#######################  | 89.99 %\n",
      "Thread #  4 progress: |#######################  | 89.99 %\n",
      "Thread # 11 progress: |#######################  | 89.99 %\n",
      "Thread #  3 progress: |#######################  | 89.99 %\n",
      "Thread #  8 progress: |#######################  | 89.99 %\n",
      "Thread #  7 progress: |#######################  | 89.99 %\n",
      "Thread #  1 progress: |#######################  | 89.99 %\n",
      "Thread # 10 progress: |#######################  | 89.99 %\n",
      "Thread #  6 progress: |#########################| 99.99 %\n",
      "Thread #  9 progress: |#########################| 99.99 %\n",
      "Thread #  2 progress: |#########################| 99.99 %\n",
      "Thread #  0 progress: |#########################| 99.99 %\n",
      "Thread # 11 progress: |#########################| 99.99 %\n",
      "Thread #  5 progress: |#########################| 99.99 %\n",
      "Thread #  7 progress: |#########################| 99.99 %\n",
      "Thread #  3 progress: |#########################| 99.99 %\n",
      "Thread #  8 progress: |#########################| 99.99 %\n",
      "Thread #  4 progress: |#########################| 99.99 %\n",
      "Thread #  1 progress: |#########################| 99.99 %\n",
      "Thread # 10 progress: |#########################| 99.99 %\n",
      "CPU times: user 2h 39min 39s, sys: 1min 36s, total: 2h 41min 15s\n",
      "Wall time: 16min 54s\n"
     ]
    }
   ],
   "source": [
    "# Measure the execution time of the following code using %%time\n",
    "%time \n",
    "\n",
    "# Read the edge graph from the specified '.edg' file using the initialized Node2Vec model.\n",
    "# The 'weighted' and 'directed' parameters are configured based on the constants WEIGHTED and DIRECTED.\n",
    "g.read_edg(edg_graph_path, weighted=WEIGHTED, directed=DIRECTED)\n",
    "\n",
    "# After reading the edge graph, simulate random walks using the Node2Vec model.\n",
    "# 'NUM_WALK' specifies the number of walks, and 'WALK_LEN' specifies the length of each walk.\n",
    "walks = g.simulate_walks(num_walks=NUM_WALK, walk_length=WALK_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd6704d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that the number of generated random walks matches the expected value\n",
    "# If the assertion is true, it means that the correct number of random walks has been generated.\n",
    "\n",
    "assert len(walks) == Node_Count * NUM_WALK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8bfa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21405226', '21402696', '21403660', '21401562', '21401454', '21401223', '21400508', '1005105', '1004249', '1002544', '1002524', '5100816', '100042795', '5100476', '5100463', '5100577', '100084968', '10100767', '10100052', '10100054', '10100767', '10101219', '10100825', '100040048', '10400618', '7203417', '8000320', '8000040', '8000303', '8000003', '8000351', '100012123', '7900702', '7101466', '7101666', '7101898', '7101926', '7102070', '7101666', '7101819', '7101816', '7101976', '100064427', '7002254', '7001735', '7002066', '7002254', '7005191', '7003686', '7003804', '6902600']\n"
     ]
    }
   ],
   "source": [
    "print(walks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a966ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 11min 54s, sys: 3min 21s, total: 9h 15min 15s\n",
      "Wall time: 2h 26min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# model = Word2Vec(sentences=walks, vector_size=128, window=7, workers=-1, negative=10)\n",
    "\n",
    "# Initialize a Word2Vec model with the given parameters.\n",
    "model = Word2Vec(walks,          # Input: Previously generated word walks\n",
    "                 hs=1,           # Hierarchical Softmax is used for training\n",
    "                 sg=1,           # Skip-gram model is employed\n",
    "                 vector_size=128,  # Size of the word embeddings\n",
    "                 window=5,       # Maximum distance between the current and predicted word within a sentence\n",
    "                 min_count=1,    # Minimum count of a word in the dataset to be considered for training\n",
    "                 workers=-1,     # Number of CPU cores to use for training (-1 means use all available cores)\n",
    "                 seed=42)        # Seed for reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65688c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Word2Vec model to a file with a specific naming convention.\n",
    "model.save('../Model/deepwalk_graph_embedding_' + GRAPH_FILE_NAME.split('.')[0] + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed27c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211861/211861 [00:01<00:00, 201291.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique 'pid' values by combining the 'pid_1' and 'pid_2' columns from the 'graph' DataFrame.\n",
    "pid_set = set(graph['pid_1'].unique()).union(graph['pid_2'].unique())\n",
    "\n",
    "# Initialize an empty list to store 'pid' and corresponding 'embedding_vector'.\n",
    "payload = []\n",
    "\n",
    "# Iterate through the 'pid_set' and retrieve embedding vectors from the Word2Vec model.\n",
    "# Use tqdm to display a progress bar.\n",
    "for pid in tqdm(pid_set):\n",
    "    try:\n",
    "        # Append a dictionary containing 'pid' and its corresponding 'embedding_vector' to the 'payload' list.\n",
    "        payload.append({'pid': pid, 'embedding_vector': model.wv[str(pid]})\n",
    "    except:\n",
    "        # If the 'pid' is not in the model's vocabulary, print a message indicating it doesn't exist.\n",
    "        print(pid, \"Not Exist\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f343721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame 'embedding_df' from the 'payload' list, containing 'pid' and 'embedding_vector' information.\n",
    "embedding_df = pd.DataFrame(payload)\n",
    "\n",
    "# Save the 'embedding_df' DataFrame to a Parquet file with a specific naming convention.\n",
    "# The 'index' is not included in the saved file.\n",
    "embedding_df.to_parquet('../Data/Embedding_Data/deepwalk_embedding_df_' + GRAPH_FILE_NAME.split('.')[0] + '.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bcbb67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e739a",
   "metadata": {},
   "source": [
    "## Node2vec\n",
    "\n",
    "Setting q > 1 will favor a BFS like exploration, while setting q < 1 will favor a DFS like exploration. Hope that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563b685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a node2vec graph using the SparseOTF (Sparse Online Training Framework) algorithm.\n",
    "g = node2vec.SparseOTF(p=1,        # Return parameter 'p' for the node2vec random walk\n",
    "                      q=0.5,      # In-out parameter 'q' for the node2vec random walk\n",
    "                      workers=-1,  \n",
    "                      verbose=True,  \n",
    "                      extend=True)  # Extend the graph data structure for online training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3fa32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread #  2 progress: |###                      | 9.99 %\n",
      "Thread #  4 progress: |###                      | 9.99 %\n",
      "Thread #  8 progress: |###                      | 9.99 %\n",
      "Thread #  7 progress: |###                      | 9.99 %\n",
      "Thread #  3 progress: |###                      | 9.99 %\n",
      "Thread #  9Thread #  progress: |###                      | 9.99 %\n",
      " 5 progress: |###                      | 9.99 %\n",
      "Thread #  6 progress: |###                      | 9.99 %\n",
      "Thread # 10 progress: |###                      | 9.99 %\n",
      "Thread #  1 progress: |###                      | 9.99 %\n",
      "Thread # 11 progress: |###                      | 9.99 %\n",
      "Thread #  0 progress: |###                      | 9.99 %\n",
      "Thread #  4 progress: |#####                    | 19.99 %\n",
      "Thread #  2 progress: |#####                    | 19.99 %\n",
      "Thread #  3 progress: |#####                    | 19.99 %\n",
      "Thread #  7 progress: |#####                    | 19.99 %\n",
      "Thread #  8 progress: |#####                    | 19.99 %\n",
      "Thread #  5 progress: |#####                    | 19.99 %\n",
      "Thread # 10 progress: |#####                    | 19.99 %\n",
      "Thread #  1 progress: |#####                    | 19.99 %\n",
      "Thread #  6 progress: |#####                    | 19.99 %\n",
      "Thread #  9 progress: |#####                    | 19.99 %\n",
      "Thread # 11 progress: |#####                    | 19.99 %\n",
      "Thread #  0 progress: |#####                    | 19.99 %\n",
      "Thread #  4 progress: |########                 | 29.99 %\n",
      "Thread #  2 progress: |########                 | 29.99 %\n",
      "Thread #  1 progress: |########                 | 29.99 %\n",
      "Thread #  7 progress: |########                 | 29.99 %\n",
      "Thread # 10 progress: |########                 | 29.99 %\n",
      "Thread #  6 progress: |########                 | 29.99 %\n",
      "Thread #  3 progress: |########                 | 29.99 %\n",
      "Thread #  8 progress: |########                 | 29.99 %\n",
      "Thread #  5 progress: |########                 | 29.99 %\n",
      "Thread # 11 progress: |########                 | 29.99 %\n",
      "Thread #  9 progress: |########                 | 29.99 %\n",
      "Thread #  0 progress: |########                 | 29.99 %\n",
      "Thread #  4 progress: |##########               | 39.99 %\n",
      "Thread # 10 progress: |##########               | 39.99 %\n",
      "Thread #  2 progress: |##########               | 39.99 %\n",
      "Thread #  6 progress: |##########               | 39.99 %\n",
      "Thread #  1 progress: |##########               | 39.99 %\n",
      "Thread #  8 progress: |##########               | 39.99 %\n",
      "Thread #  5 progress: |##########               | 39.99 %\n",
      "Thread # 11 progress: |##########               | 39.99 %\n",
      "Thread #  7 progress: |##########               | 39.99 %\n",
      "Thread #  9 progress: |##########               | 39.99 %\n",
      "Thread #  3 progress: |##########               | 39.99 %\n",
      "Thread #  0 progress: |##########               | 39.99 %\n",
      "Thread #  4 progress: |#############            | 49.99 %\n",
      "Thread # 10 progress: |#############            | 49.99 %\n",
      "Thread # 11 progress: |#############            | 49.99 %\n",
      "Thread #  7 progress: |#############            | 49.99 %\n",
      "Thread #  2 progress: |#############            | 49.99 %\n",
      "Thread #  1 progress: |#############            | 49.99 %\n",
      "Thread #  8 progress: |#############            | 49.99 %\n",
      "Thread #  6 progress: |#############            | 49.99 %\n",
      "Thread #  5 progress: |#############            | 49.99 %\n",
      "Thread #  9 progress: |#############            | 49.99 %\n",
      "Thread #  3 progress: |#############            | 49.99 %\n",
      "Thread #  0 progress: |#############            | 49.99 %\n",
      "Thread #  4 progress: |###############          | 59.99 %\n",
      "Thread # 10 progress: |###############          | 59.99 %\n",
      "Thread # 11 progress: |###############          | 59.99 %\n",
      "Thread #  1 progress: |###############          | 59.99 %\n",
      "Thread #  2 progress: |###############          | 59.99 %\n",
      "Thread #  8 progress: |###############          | 59.99 %\n",
      "Thread #  3 progress: |###############          | 59.99 %\n",
      "Thread #  6 progress: |###############          | 59.99 %\n",
      "Thread #  7 progress: |###############          | 59.99 %\n",
      "Thread #  9 progress: |###############          | 59.99 %\n",
      "Thread #  5 progress: |###############          | 59.99 %\n",
      "Thread #  0 progress: |###############          | 59.99 %\n",
      "Thread #  4 progress: |##################       | 69.99 %\n",
      "Thread # 10 progress: |##################       | 69.99 %\n",
      "Thread # 11 progress: |##################       | 69.99 %\n",
      "Thread #  1 progress: |##################       | 69.99 %\n",
      "Thread #  2 progress: |##################       | 69.99 %\n",
      "Thread #  8 progress: |##################       | 69.99 %\n",
      "Thread #  Thread #  6 progress: |##################       | 69.99 %\n",
      "7 progress: |##################       | 69.99 %\n",
      "Thread #  3 progress: |##################       | 69.99 %\n",
      "Thread #  9 progress: |##################       | 69.99 %\n",
      "Thread #  5 progress: |##################       | 69.99 %\n",
      "Thread #  0 progress: |##################       | 69.99 %\n",
      "Thread #  4 progress: |####################     | 79.99 %\n",
      "Thread # 10 progress: |####################     | 79.99 %\n",
      "Thread #  1 progress: |####################     | 79.99 %\n",
      "Thread #  2 progress: |####################     | 79.99 %\n",
      "Thread #  8 progress: |####################     | 79.99 %\n",
      "Thread # 11 progress: |####################     | 79.99 %\n",
      "Thread #  7 progress: |####################     | 79.99 %\n",
      "Thread #  6 progress: |####################     | 79.99 %\n",
      "Thread #  3 progress: |####################     | 79.99 %\n",
      "Thread #  5 progress: |####################     | 79.99 %\n",
      "Thread #  9 progress: |####################     | 79.99 %\n",
      "Thread #  0 progress: |####################     | 79.99 %\n",
      "Thread #  4 progress: |#######################  | 89.99 %\n",
      "Thread #  1 progress: |#######################  | 89.99 %\n",
      "Thread #  2 progress: |#######################  | 89.99 %\n",
      "Thread # 10 progress: |#######################  | 89.99 %\n",
      "Thread #  8 progress: |#######################  | 89.99 %\n",
      "Thread # 11 progress: |#######################  | 89.99 %\n",
      "Thread #  3 progress: |#######################  | 89.99 %\n",
      "Thread #  7 progress: |#######################  | 89.99 %\n",
      "Thread #  6 progress: |#######################  | 89.99 %\n",
      "Thread #  9 progress: |#######################  | 89.99 %\n",
      "Thread #  5 progress: |#######################  | 89.99 %\n",
      "Thread #  0 progress: |#######################  | 89.99 %\n",
      "Thread #  4 progress: |#########################| 99.99 %\n",
      "Thread #  1 progress: |#########################| 99.99 %\n",
      "Thread #  2 progress: |#########################| 99.99 %\n",
      "Thread #  8 progress: |#########################| 99.99 %\n",
      "Thread # 11 progress: |#########################| 99.99 %\n",
      "Thread # 10 progress: |#########################| 99.99 %\n",
      "Thread #  3 progress: |#########################| 99.99 %\n",
      "Thread #  7 progress: |#########################| 99.99 %\n",
      "Thread #  6 progress: |#########################| 99.99 %\n",
      "Thread #  9 progress: |#########################| 99.99 %\n",
      "Thread #  5 progress: |#########################| 99.99 %\n",
      "Thread #  0 progress: |#########################| 99.99 %\n",
      "CPU times: user 2h 43min 10s, sys: 4min 14s, total: 2h 47min 25s\n",
      "Wall time: 16min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read the edge data from the file specified by 'edg_graph_path' into the node2vec graph 'g'.\n",
    "# The 'weighted' and 'directed' flags control how the graph is constructed.\n",
    "g.read_edg(edg_graph_path, weighted=WEIGHTED, directed=DIRECTED)\n",
    "\n",
    "# Simulate random walks on the graph to generate 'walks'.\n",
    "# 'num_walks' controls the number of walks to perform, and 'walk_length' is the length of each walk.\n",
    "walks = g.simulate_walks(num_walks=NUM_WALK, walk_length=WALK_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18fc5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that the total number of generated walks ('walks') is equal to the expected value,\n",
    "# which is calculated as the product of 'Node_Count' and 'NUM_WALK'.\n",
    "assert len(walks) == Node_Count * NUM_WALK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e440c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11500381', '11500310', '11500720', '11500159', '4804295', '5100816', '5100817', '100041309', '5100536', '5100597', '100041309', '5100818', '5100816', '5100875', '5100719', '5100564', '5100577', '100015591', '5100895', '100015591', '5100876', '5100888', '5100860', '5100852', '3601283', '3601605', '3601603', '3600661', '3601495', '3601632', '3601638', '3601015', '3600980', '3600661', '3600937', '3600666', '3600937', '3600661', '3600666', '3601347', '3600182', '3601489', '3601537', '3600937', '3601437', '3601421', '3601286', '3601454', '3600999', '3601514', '2702331']\n"
     ]
    }
   ],
   "source": [
    "print(walks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa59ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 27min 53s, sys: 1min 1s, total: 4h 28min 55s\n",
      "Wall time: 1h 9min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create a Word2Vec model using the generated 'walks' dataset.\n",
    "model = Word2Vec(walks,             # Input: Previously generated walks\n",
    "                 hs=1,              # Use hierarchical softmax for training\n",
    "                 sg=1,              # Use skip-gram model for training\n",
    "                 vector_size=128,  # Set the size of the word embeddings\n",
    "                 window=5,          # Maximum distance between the current and predicted word within a sentence\n",
    "                 min_count=1,       # Minimum count of a word in the dataset to be considered for training\n",
    "                 workers=4,         # Number of CPU cores to use for training (adjust as needed)\n",
    "                 seed=42)           # Set a seed for reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5288e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Word2Vec model to a file\n",
    "model.save('../Model/node2vec_graph_embedding_' + GRAPH_FILE_NAME.split('.')[0] + '.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9cc9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211861/211861 [00:01<00:00, 182278.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a set 'pid_set' by combining the unique 'pid' values from 'pid_1' and 'pid_2' columns in the 'graph' DataFrame.\n",
    "pid_set = set(graph['pid_1'].unique()).union(graph['pid_2'].unique())\n",
    "\n",
    "# Initialize an empty list 'payload' to store 'pid' and corresponding 'embedding_vector'.\n",
    "payload = []\n",
    "\n",
    "# Iterate through the 'pid_set' and attempt to retrieve the embedding vectors from the Word2Vec model.\n",
    "# The 'tqdm' is used to display a progress bar.\n",
    "for pid in tqdm(pid_set):\n",
    "    try:\n",
    "        # Append a dictionary containing 'pid' and its corresponding 'embedding_vector' to the 'payload' list.\n",
    "        payload.append({'pid': pid, 'embedding_vector': model.wv[str(pid]})\n",
    "    except:\n",
    "        # If the 'pid' is not found in the model's vocabulary, print a message indicating it doesn't exist.\n",
    "        print(pid, \"Not Exist\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bff15eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame 'embedding_df' from the 'payload' list, which contains 'pid' and 'embedding_vector' information.\n",
    "embedding_df = pd.DataFrame(payload)\n",
    "\n",
    "# Save the 'embedding_df' DataFrame to a Parquet file with a specific naming convention.\n",
    "# The 'index' is not included in the saved file.\n",
    "embedding_df.to_parquet('../Data/Embedding_Data/node2vec_embedding_df_' + GRAPH_FILE_NAME.split('.')[0] + '.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37fb067e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>embedding_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17301504</td>\n",
       "      <td>[0.44851154, 0.40735474, -0.172185, 0.07374085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17301505</td>\n",
       "      <td>[0.47892618, 0.20487863, 0.021507299, -0.62510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17301506</td>\n",
       "      <td>[0.25423482, 0.47845665, -0.001093431, 0.03616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17301507</td>\n",
       "      <td>[-0.10483544, 0.22859468, -0.16854355, 0.21888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17301508</td>\n",
       "      <td>[0.83427334, 0.5198858, 0.011705197, 0.4507888...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pid                                   embedding_vector\n",
       "0  17301504  [0.44851154, 0.40735474, -0.172185, 0.07374085...\n",
       "1  17301505  [0.47892618, 0.20487863, 0.021507299, -0.62510...\n",
       "2  17301506  [0.25423482, 0.47845665, -0.001093431, 0.03616...\n",
       "3  17301507  [-0.10483544, 0.22859468, -0.16854355, 0.21888...\n",
       "4  17301508  [0.83427334, 0.5198858, 0.011705197, 0.4507888..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aead848",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c5bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
